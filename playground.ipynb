{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e81d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### reload magic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.data_loaders.pl_data_loader import PLDataLoader\n",
    "\n",
    "config_file = './exp_config/exp1.yml'\n",
    "with open(config_file, \"r\") as content:\n",
    "    config = yaml.safe_load(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7faa9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366595/366595 [00:02<00:00, 158921.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainLoader  instantiate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157512/157512 [00:00<00:00, 158149.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadarLoader  instantiate.\n",
      "===start cross comparison of time lists===\n",
      "359945\n"
     ]
    }
   ],
   "source": [
    "my_loader = PLDataLoader(\n",
    "    data_meta_info=config['train_config']['data_meta_info'], **config['train_config']['data_loader_params']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfeb00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### reload magic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import os, sys\n",
    "import socket, pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "# os.environ['ROOT_DATA_DIR']='/work/dong1128/database'\n",
    "# os.environ['ROOT_DATA_DIR']='/bk2/handsomedong/DLRA_database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ef68ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mearly_stopping\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m     11\u001b[0m \u001b[39m# from core.data_loader_type import DataLoaderType\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# from core.enum import DataType\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# from core.loss_type import BlockAggregationMode, LossType\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# from core.model_type import ModelType\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_loader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpl_data_loader_module\u001b[39;00m \u001b[39mimport\u001b[39;00m PLDataLoader\n\u001b[1;32m     16\u001b[0m \u001b[39m# from utils.run_utils import get_model, parse_date_end, parse_date_start, parse_dict\u001b[39;00m\n",
      "File \u001b[0;32m~/deepQPF_research/data_loader/pl_data_loader_module.py:14\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      6\u001b[0m \u001b[39m# from core.data_loader_type import DataLoaderType\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# from core.enum import DataType\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# from data_loaders.classifier.classifier_data_loader import ClassifierDataLoader\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# from data_loaders.data_loader_all_loaded import DataLoaderAllLoaded\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# from data_loaders.data_loader_grid import DataLoaderGrid\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# from data_loaders.data_loader_with_prior import DataLoaderWithPrior\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPLDataLoader\u001b[39;00m(LightningDataModule):\n\u001b[1;32m     15\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     16\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     17\u001b[0m         train_start: datetime,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m         num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[1;32m     39\u001b[0m     ):\n\u001b[1;32m     41\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/deepQPF_research/data_loader/pl_data_loader_module.py:21\u001b[0m, in \u001b[0;36mPLDataLoader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPLDataLoader\u001b[39;00m(LightningDataModule):\n\u001b[1;32m     15\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     16\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     17\u001b[0m         train_start: datetime,\n\u001b[1;32m     18\u001b[0m         train_end: datetime,\n\u001b[1;32m     19\u001b[0m         val_start: datetime,\n\u001b[1;32m     20\u001b[0m         val_end: datetime,\n\u001b[0;32m---> 21\u001b[0m         data_type\u001b[39m=\u001b[39mDataType\u001b[39m.\u001b[39mNONEATALL,\n\u001b[1;32m     22\u001b[0m         dloader_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m         input_len\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m         target_len\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m         target_avg_length\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[1;32m     26\u001b[0m         target_offset\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     27\u001b[0m         threshold\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     28\u001b[0m         hourly_data\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m         hetero_data\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m         residual\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m         img_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m         prior_dtype\u001b[39m=\u001b[39mDataType\u001b[39m.\u001b[39mNONEATALL,\n\u001b[1;32m     33\u001b[0m         ith_grid\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     34\u001b[0m         pad_grid\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m         random_std\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     36\u001b[0m         sampling_rate\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     38\u001b[0m         num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[1;32m     39\u001b[0m     ):\n\u001b[1;32m     41\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     42\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tr_s \u001b[39m=\u001b[39m train_start\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataType' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# from core.data_loader_type import DataLoaderType\n",
    "# from core.enum import DataType\n",
    "# from core.loss_type import BlockAggregationMode, LossType\n",
    "# from core.model_type import ModelType\n",
    "from data_loader.pl_data_loader_module import PLDataLoader\n",
    "# from utils.run_utils import get_model, parse_date_end, parse_date_start, parse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9bb0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loplhcctr1679204578953-zbn2l 23-03-20-20:48:18\n",
      "Python version 3.8.16 (default, Mar  2 2023, 03:21:46) \n",
      "[GCC 11.2.0]\n",
      "CUDA_HOME /usr/local/cuda\n",
      "CudaToolKit Version None\n",
      "torch Version 2.0.0\n",
      "torchvision Version 0.15.0\n"
     ]
    }
   ],
   "source": [
    "print(socket.gethostname(), datetime.now().strftime(\"%y-%m-%d-%H:%M:%S\"))\n",
    "print('Python version', sys.version)\n",
    "print('CUDA_HOME', CUDA_HOME)\n",
    "print('CudaToolKit Version', torch.version.cuda)\n",
    "print('torch Version', torch.__version__)\n",
    "print('torchvision Version', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser() #--代表是optional\n",
    "# 若在命令列有輸入值，才會進行「type」的運算（預設string）；若無，直接回傳default\n",
    "parser.add_argument('--dloader_type', type=DataLoaderType.from_name, default=DataLoaderType.Native)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--train_start', type=parse_date_start, default=datetime(2015, 1, 1))\n",
    "parser.add_argument('--train_end', type=parse_date_end, default=datetime(2015, 1, 31, 23, 50))\n",
    "parser.add_argument('--val_start', type=parse_date_start, default=datetime(2021, 6, 1))\n",
    "parser.add_argument('--val_end', type=parse_date_end, default=datetime(2021, 6, 30, 23, 50))\n",
    "parser.add_argument('--loss_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--log_dir', type=str, default='logs')\n",
    "parser.add_argument('--data_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--model_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--checkpoints_path',\n",
    "                    type=str,\n",
    "                    default=(os.getcwd() + '/checkpoints/'),\n",
    "                    help='Full path to the directory where model checkpoints are [to be] saved')\n",
    "# 加入Trainer參數\n",
    "parser = Trainer.add_argparse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(['--batch_size','32',\n",
    "                          '--data_kwargs','type:21,sampling_rate:6,target_len:3',\n",
    "                          '--model_kwargs','type:BalancedGRUAdvPONI,teach_force:0.5'\n",
    "                         ]) # 回傳一個args就可以用了\n",
    "print('dloader_type:', args.dloader_type,'\\n\\ndata_kwargs:',args.data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73530c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 8\n",
    "input_shape = (120, 120)\n",
    "loss_type = int(args.loss_kwargs.get('type', LossType.WeightedMAE))\n",
    "loss_aggregation_mode = int(args.loss_kwargs.get('aggregation_mode', BlockAggregationMode.MAX))\n",
    "loss_kernel_size = int(args.loss_kwargs.get('kernel_size', 5))\n",
    "residual_loss = bool(int(args.loss_kwargs.get('residual_loss', 0)))\n",
    "mixing_weight = float(args.loss_kwargs.get('w', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kwargs = {\n",
    "    'type': loss_type,\n",
    "    'aggregation_mode': loss_aggregation_mode,\n",
    "    'kernel_size': loss_kernel_size,\n",
    "    'residual_loss': residual_loss,\n",
    "    'w': mixing_weight\n",
    "}\n",
    "if loss_type in [LossType.SSIMBasedLoss, LossType.NormalizedSSIMBasedLoss]:\n",
    "    loss_kwargs['mae_w'] = float(args.loss_kwargs.get('mae_w', 0.1))\n",
    "    loss_kwargs['ssim_w'] = float(args.loss_kwargs.get('ssim_w', 0.02))\n",
    "\n",
    "data_kwargs = {\n",
    "    'data_type': int(args.data_kwargs.get('type', DataType.RAIN+DataType.RADAR)),\n",
    "    'residual': bool(int(args.data_kwargs.get('residual', 0))),\n",
    "    'target_offset': int(args.data_kwargs.get('target_offset', 0)),\n",
    "    'target_len': int(args.data_kwargs.get('target_len', 3)),\n",
    "    'input_len': int(args.data_kwargs.get('input_len', 6)),\n",
    "    'hourly_data': bool(int(args.data_kwargs.get('hourly_data', 0))),\n",
    "    'hetero_data': bool(int(args.data_kwargs.get('hetero_data', 0))),\n",
    "    'sampling_rate': int(args.data_kwargs.get('sampling_rate', 5)),\n",
    "    'prior_dtype': int(args.data_kwargs.get('prior', DataType.NONEATALL)),\n",
    "    'random_std': int(args.data_kwargs.get('random_std', 0)),\n",
    "    'ith_grid': int(args.data_kwargs.get('ith_grid', -1)),\n",
    "    'pad_grid': int(args.data_kwargs.get('pad_grid', 10)),\n",
    "    'threshold': float(args.data_kwargs.get('threshold', 0.5)),\n",
    "}\n",
    "model_kwargs = {\n",
    "    'adv_w': float(args.model_kwargs.get('adv_w', 0.01)),\n",
    "    'model_type': ModelType.from_name(args.model_kwargs.get('type', 'BalancedGRUAdverserialAttention')),\n",
    "    'dis_d': int(args.model_kwargs.get('dis_d', 3)),\n",
    "    'teach_force':float(args.model_kwargs.get('teach_force', 0)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934bf9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = PLDataLoader(\n",
    "    args.train_start,\n",
    "    args.train_end,\n",
    "    args.val_start,\n",
    "    args.val_end,\n",
    "    img_size=input_shape,\n",
    "    dloader_type=args.dloader_type,\n",
    "    **data_kwargs,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9838ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    args.train_start,\n",
    "    args.train_end,\n",
    "    model_kwargs,\n",
    "    loss_kwargs,\n",
    "    data_kwargs,\n",
    "    args.checkpoints_path,\n",
    "    args.log_dir,\n",
    "    data_loader_info=dm.model_related_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir='logs', name=ModelType.name(model_kwargs['model_type']))\n",
    "logger.log_hyperparams(args)\n",
    "# logger.experiment.tag({'input_len': data_kwargs['input_len'], 'target_len': data_kwargs['target_len']})\n",
    "checkpoint_callback = model.get_checkpoint_callback()\n",
    "trainer = Trainer.from_argparse_args(\n",
    "    args, \n",
    "    gpus=1,\n",
    "    max_epochs=50, \n",
    "    fast_dev_run=False, \n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    ")\n",
    "trainer.fit(model, dm)  #.fit同時做了train and validation\n",
    "#default max epochs for pl is 1000\n",
    "\n",
    "# if args.evaluate_ckp_path:\n",
    "#     checkpoint = torch.load(args.evaluate_ckp_path)\n",
    "#     _ = model.load_state_dict(checkpoint['state_dict'])\n",
    "#     trainer.test(model, test_dataloaders=dm.val_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlra_kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2f804bfec06f53216ee7b06b06133345248b8b48c2d184ed52a2723fca76428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
